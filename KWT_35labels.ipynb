{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 0. Requirements & Config"
      ],
      "metadata": {
        "id": "ZXluF6Ucsqdd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "requirements_str = \"\"\"\n",
        "torch>=1.7.0\n",
        "librosa\n",
        "audiomentations\n",
        "pydub\n",
        "tqdm\n",
        "einops\"\"\"\n",
        "\n",
        "with open(\"requirements.txt\", \"w\") as f:\n",
        "    f.write(requirements_str)\n",
        "\n",
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "_Hbr-ykPsoz5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4745834b-6093-4f65-f351-e609b490cbc7"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 2)) (2.8.0+cu126)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 3)) (0.11.0)\n",
            "Collecting audiomentations (from -r requirements.txt (line 4))\n",
            "  Downloading audiomentations-0.42.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 5)) (0.25.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 6)) (4.67.1)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 7)) (0.8.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->-r requirements.txt (line 2)) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->-r requirements.txt (line 2)) (4.14.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->-r requirements.txt (line 2)) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->-r requirements.txt (line 2)) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->-r requirements.txt (line 2)) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->-r requirements.txt (line 2)) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->-r requirements.txt (line 2)) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->-r requirements.txt (line 2)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->-r requirements.txt (line 2)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->-r requirements.txt (line 2)) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->-r requirements.txt (line 2)) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->-r requirements.txt (line 2)) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->-r requirements.txt (line 2)) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->-r requirements.txt (line 2)) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->-r requirements.txt (line 2)) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->-r requirements.txt (line 2)) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->-r requirements.txt (line 2)) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->-r requirements.txt (line 2)) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->-r requirements.txt (line 2)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->-r requirements.txt (line 2)) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->-r requirements.txt (line 2)) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->-r requirements.txt (line 2)) (3.4.0)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.12/dist-packages (from librosa->-r requirements.txt (line 3)) (3.0.1)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.12/dist-packages (from librosa->-r requirements.txt (line 3)) (0.60.0)\n",
            "Requirement already satisfied: numpy>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from librosa->-r requirements.txt (line 3)) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from librosa->-r requirements.txt (line 3)) (1.16.1)\n",
            "Requirement already satisfied: scikit-learn>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from librosa->-r requirements.txt (line 3)) (1.6.1)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.12/dist-packages (from librosa->-r requirements.txt (line 3)) (1.5.1)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from librosa->-r requirements.txt (line 3)) (4.4.2)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.12/dist-packages (from librosa->-r requirements.txt (line 3)) (0.13.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.12/dist-packages (from librosa->-r requirements.txt (line 3)) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.12/dist-packages (from librosa->-r requirements.txt (line 3)) (0.5.0.post1)\n",
            "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.12/dist-packages (from librosa->-r requirements.txt (line 3)) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.12/dist-packages (from librosa->-r requirements.txt (line 3)) (1.1.1)\n",
            "Collecting numpy-minmax<1,>=0.3.0 (from audiomentations->-r requirements.txt (line 4))\n",
            "  Downloading numpy_minmax-0.5.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
            "Collecting numpy-rms<1,>=0.4.2 (from audiomentations->-r requirements.txt (line 4))\n",
            "  Downloading numpy_rms-0.6.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.5 kB)\n",
            "Collecting python-stretch<1,>=0.3.1 (from audiomentations->-r requirements.txt (line 4))\n",
            "  Downloading python_stretch-0.3.1-cp312-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from lazy_loader>=0.1->librosa->-r requirements.txt (line 3)) (25.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba>=0.51.0->librosa->-r requirements.txt (line 3)) (0.43.0)\n",
            "Requirement already satisfied: cffi>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from numpy-minmax<1,>=0.3.0->audiomentations->-r requirements.txt (line 4)) (1.17.1)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from pooch>=1.1->librosa->-r requirements.txt (line 3)) (4.3.8)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from pooch>=1.1->librosa->-r requirements.txt (line 3)) (2.32.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.1.0->librosa->-r requirements.txt (line 3)) (3.6.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.7.0->-r requirements.txt (line 2)) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.7.0->-r requirements.txt (line 2)) (3.0.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.0.0->numpy-minmax<1,>=0.3.0->audiomentations->-r requirements.txt (line 4)) (2.22)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa->-r requirements.txt (line 3)) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa->-r requirements.txt (line 3)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa->-r requirements.txt (line 3)) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa->-r requirements.txt (line 3)) (2025.8.3)\n",
            "Downloading audiomentations-0.42.0-py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.5/86.5 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy_minmax-0.5.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Downloading numpy_rms-0.6.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18 kB)\n",
            "Downloading python_stretch-0.3.1-cp312-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (109 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.4/109.4 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: python-stretch, numpy-rms, numpy-minmax, audiomentations\n",
            "Successfully installed audiomentations-0.42.0 numpy-minmax-0.5.0 numpy-rms-0.6.0 python-stretch-0.3.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conf_str = \"\"\"# sample config to run a demo training of 20 epochs\n",
        "\n",
        "data_root: ./data/\n",
        "train_list_file: ./data/training_list.txt\n",
        "val_list_file: ./data/validation_list.txt\n",
        "test_list_file: ./data/testing_list.txt\n",
        "label_map: ./data/label_map.json\n",
        "\n",
        "pkl_root: ./google_speech_commands_v2/\n",
        "pkl_train: ./google_speech_commands_v2/train_dataset.pkl\n",
        "pkl_test: ./google_speech_commands_v2/test_dataset.pkl\n",
        "\n",
        "exp:\n",
        "    exp_dir: ./runs\n",
        "    exp_name: exp-0.0.1\n",
        "    device: auto\n",
        "    log_freq: 20    # log every l_f steps\n",
        "    log_to_file: False\n",
        "    log_to_stdout: True\n",
        "    val_freq: 1    # validate every v_f epochs\n",
        "    n_workers: 1\n",
        "    pin_memory: True\n",
        "\n",
        "\n",
        "hparams:\n",
        "    seed: 0\n",
        "    batch_size: 512\n",
        "    n_epochs: 20\n",
        "    l_smooth: 0.1\n",
        "\n",
        "    audio:\n",
        "        sr: 16000\n",
        "        n_mels: 40\n",
        "        n_fft: 480\n",
        "        win_length: 480\n",
        "        hop_length: 160\n",
        "        center: False\n",
        "\n",
        "    model:\n",
        "        name: kwt-2 # if name is provided below settings will be ignored during model creation\n",
        "        input_res: [40, 98]\n",
        "        patch_res: [40, 1]\n",
        "        num_classes: 35\n",
        "        mlp_dim: 256\n",
        "        dim: 64\n",
        "        heads: 1\n",
        "        depth: 12\n",
        "        dropout: 0.0\n",
        "        emb_dropout: 0.1\n",
        "        pre_norm: False\n",
        "\n",
        "    optimizer:\n",
        "        opt_type: adamw\n",
        "        opt_kwargs:\n",
        "          lr: 0.001\n",
        "          weight_decay: 0.1\n",
        "\n",
        "    scheduler:\n",
        "        n_warmup: 10\n",
        "        max_epochs: 140\n",
        "        scheduler_type: cosine_annealing\n",
        "\n",
        "    augment:\n",
        "        spec_aug:\n",
        "            n_time_masks: 2\n",
        "            time_mask_width: 25\n",
        "            n_freq_masks: 2\n",
        "            freq_mask_width: 7\"\"\"\n",
        "\n",
        "!mkdir -p configs\n",
        "with open(\"configs/kwt2_colab.yaml\", \"w+\") as f:\n",
        "  f.write(conf_str)\n",
        "\n",
        "conf_file = \"configs/kwt2_colab.yaml\""
      ],
      "metadata": {
        "id": "C_-GpO-w--Bo"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- `config_parser.py` - `get_config`"
      ],
      "metadata": {
        "id": "-aBNxV1M8AIN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import yaml\n",
        "import os\n",
        "import torch\n",
        "import sys\n",
        "\n",
        "\n",
        "def get_config(config_file: str) -> dict:\n",
        "\n",
        "    with open(config_file, \"r\") as f:\n",
        "        base_config = yaml.load(f, Loader=yaml.FullLoader)\n",
        "\n",
        "    if base_config[\"exp\"][\"device\"] == \"auto\":\n",
        "        base_config[\"exp\"][\"device\"] = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        base_config[\"hparams\"][\"device\"] = base_config[\"exp\"][\"device\"]\n",
        "\n",
        "    return base_config"
      ],
      "metadata": {
        "id": "O_Sp-89R8JCg"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Define the model"
      ],
      "metadata": {
        "id": "7qg4s10IrvUS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.fft\n",
        "import torch.nn.functional as F\n",
        "from torch import nn, einsum\n",
        "\n",
        "from einops import rearrange, repeat\n",
        "from einops.layers.torch import Rearrange\n",
        "\n",
        "\n",
        "# Basically vision transformer, ViT that accepts MFCC + SpecAug. Refer to:\n",
        "# https://github.com/lucidrains/vit-pytorch/blob/main/vit_pytorch/vit.py\n",
        "\n",
        "\n",
        "class PreNorm(nn.Module):\n",
        "    def __init__(self, dim, fn):\n",
        "        super().__init__()\n",
        "        self.norm = nn.LayerNorm(dim)\n",
        "        self.fn = fn\n",
        "\n",
        "    def forward(self, x, **kwargs):\n",
        "        return self.fn(self.norm(x), **kwargs)\n",
        "\n",
        "\n",
        "class PostNorm(nn.Module):\n",
        "    def __init__(self, dim, fn):\n",
        "        super().__init__()\n",
        "        self.norm = nn.LayerNorm(dim)\n",
        "        self.fn = fn\n",
        "\n",
        "    def forward(self, x, **kwargs):\n",
        "        return self.norm(self.fn(x, **kwargs))\n",
        "\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, dim, hidden_dim, dropout = 0.):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_dim, dim),\n",
        "            nn.Dropout(dropout)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "\n",
        "class Attention(nn.Module):\n",
        "    def __init__(self, dim, heads = 8, dim_head = 64, dropout = 0.):\n",
        "        super().__init__()\n",
        "        inner_dim = dim_head *  heads\n",
        "        project_out = not (heads == 1 and dim_head == dim)\n",
        "\n",
        "        self.heads = heads\n",
        "        self.scale = dim_head ** -0.5\n",
        "\n",
        "        self.attend = nn.Softmax(dim = -1)\n",
        "        self.to_qkv = nn.Linear(dim, inner_dim * 3, bias = False)\n",
        "\n",
        "        self.to_out = nn.Sequential(\n",
        "            nn.Linear(inner_dim, dim),\n",
        "            nn.Dropout(dropout)\n",
        "        ) if project_out else nn.Identity()\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, n, _, h = *x.shape, self.heads\n",
        "        qkv = self.to_qkv(x).chunk(3, dim = -1)\n",
        "        q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> b h n d', h = h), qkv)\n",
        "\n",
        "        dots = einsum('b h i d, b h j d -> b h i j', q, k) * self.scale\n",
        "\n",
        "        attn = self.attend(dots)\n",
        "\n",
        "        out = einsum('b h i j, b h j d -> b h i d', attn, v)\n",
        "        out = rearrange(out, 'b h n d -> b n (h d)')\n",
        "        return self.to_out(out)\n",
        "\n",
        "\n",
        "class Transformer(nn.Module):\n",
        "    def __init__(self, dim, depth, heads, dim_head, mlp_dim, pre_norm=True, dropout = 0.):\n",
        "        super().__init__()\n",
        "        self.layers = nn.ModuleList([])\n",
        "\n",
        "        P_Norm = PreNorm if pre_norm else PostNorm\n",
        "\n",
        "        for _ in range(depth):\n",
        "            self.layers.append(nn.ModuleList([\n",
        "                P_Norm(dim, Attention(dim, heads = heads, dim_head = dim_head, dropout = dropout)),\n",
        "                P_Norm(dim, FeedForward(dim, mlp_dim, dropout = dropout))\n",
        "            ]))\n",
        "\n",
        "    def forward(self, x):\n",
        "        for attn, ff in self.layers:\n",
        "            x = attn(x) + x\n",
        "            x = ff(x) + x\n",
        "        return x\n",
        "\n",
        "\n",
        "class KWT(nn.Module):\n",
        "    def __init__(self, input_res, patch_res, num_classes, dim, depth, heads, mlp_dim, pool = 'cls', channels = 1, dim_head = 64, dropout = 0., emb_dropout = 0., pre_norm = True, **kwargs):\n",
        "        super().__init__()\n",
        "\n",
        "        num_patches = int(input_res[0]/patch_res[0] * input_res[1]/patch_res[1])\n",
        "\n",
        "        patch_dim = channels * patch_res[0] * patch_res[1]\n",
        "        assert pool in {'cls', 'mean'}, 'pool type must be either cls (cls token) or mean (mean pooling)'\n",
        "\n",
        "        self.to_patch_embedding = nn.Sequential(\n",
        "            Rearrange('b c (h p1) (w p2) -> b (h w) (p1 p2 c)', p1 = patch_res[0], p2 = patch_res[1]),\n",
        "            nn.Linear(patch_dim, dim),\n",
        "        )\n",
        "\n",
        "        self.pos_embedding = nn.Parameter(torch.randn(1, num_patches + 1, dim))\n",
        "        self.cls_token = nn.Parameter(torch.randn(1, 1, dim))\n",
        "        self.dropout = nn.Dropout(emb_dropout)\n",
        "\n",
        "        self.transformer = Transformer(dim, depth, heads, dim_head, mlp_dim, pre_norm, dropout)\n",
        "\n",
        "        self.pool = pool\n",
        "        self.to_latent = nn.Identity()\n",
        "\n",
        "        self.mlp_head = nn.Sequential(\n",
        "            nn.LayerNorm(dim),\n",
        "            nn.Linear(dim, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.to_patch_embedding(x)\n",
        "\n",
        "        b, n, _ = x.shape\n",
        "\n",
        "        cls_tokens = repeat(self.cls_token, '() n d -> b n d', b = b)\n",
        "        x = torch.cat((cls_tokens, x), dim=1)\n",
        "        x += self.pos_embedding[:, :(n + 1)]\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = self.transformer(x)\n",
        "\n",
        "        x = x.mean(dim = 1) if self.pool == 'mean' else x[:, 0]\n",
        "\n",
        "        x = self.to_latent(x)\n",
        "        return self.mlp_head(x)\n",
        "\n",
        "\n",
        "def kwt_from_name(model_name: str):\n",
        "\n",
        "    models = {\n",
        "        \"kwt-1\": {\n",
        "            \"input_res\": [40, 98],\n",
        "            \"patch_res\": [40, 1],\n",
        "            \"num_classes\": 35,\n",
        "            \"mlp_dim\": 256,\n",
        "            \"dim\": 64,\n",
        "            \"heads\": 1,\n",
        "            \"depth\": 12,\n",
        "            \"dropout\": 0.0,\n",
        "            \"emb_dropout\": 0.1,\n",
        "            \"pre_norm\": False\n",
        "        },\n",
        "\n",
        "        \"kwt-2\": {\n",
        "            \"input_res\": [40, 98],\n",
        "            \"patch_res\": [40, 1],\n",
        "            \"num_classes\": 35,\n",
        "            \"mlp_dim\": 512,\n",
        "            \"dim\": 128,\n",
        "            \"heads\": 2,\n",
        "            \"depth\": 12,\n",
        "            \"dropout\": 0.0,\n",
        "            \"emb_dropout\": 0.1,\n",
        "            \"pre_norm\": False\n",
        "        },\n",
        "\n",
        "        \"kwt-3\": {\n",
        "            \"input_res\": [40, 98],\n",
        "            \"patch_res\": [40, 1],\n",
        "            \"num_classes\": 35,\n",
        "            \"mlp_dim\": 768,\n",
        "            \"dim\": 192,\n",
        "            \"heads\": 3,\n",
        "            \"depth\": 12,\n",
        "            \"dropout\": 0.0,\n",
        "            \"emb_dropout\": 0.1,\n",
        "            \"pre_norm\": False\n",
        "        }\n",
        "    }\n",
        "\n",
        "    assert model_name in models.keys(), f\"Unsupported model_name {model_name}; must be one of {list(models.keys())}\"\n",
        "\n",
        "    return KWT(**models[model_name])"
      ],
      "metadata": {
        "id": "yiHaFA67ru0a"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Dataset functions"
      ],
      "metadata": {
        "id": "fSkm7wq13uzm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1 Spectrogram augmentation"
      ],
      "metadata": {
        "id": "zaihmLp2vZtO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import numba as nb\n",
        "import librosa\n",
        "\n",
        "#@nb.jit(nopython=True, cache=True)\n",
        "@nb.jit(nopython=True)\n",
        "def spec_augment(mel_spec: np.ndarray, n_time_masks: int, time_mask_width: int, n_freq_masks: int, freq_mask_width: int):\n",
        "    offset, begin = 0, 0\n",
        "\n",
        "    for _ in range(n_time_masks):\n",
        "        offset = np.random.randint(0, time_mask_width)\n",
        "        begin = np.random.randint(0, mel_spec.shape[1] - offset)\n",
        "        mel_spec[:, begin: begin + offset] = 0.0\n",
        "\n",
        "    for _ in range(n_freq_masks):\n",
        "        offset = np.random.randint(0, freq_mask_width)\n",
        "        begin = np.random.randint(0, mel_spec.shape[0] - offset)\n",
        "        mel_spec[begin: begin + offset, :] = 0.0\n",
        "\n",
        "    return mel_spec\n"
      ],
      "metadata": {
        "id": "RiZ4Nqxhv6qC"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2 Dataset wrapper and get loader"
      ],
      "metadata": {
        "id": "0Sf-ORmX4Pkr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import ConcatDataset, Dataset\n",
        "import pickle\n",
        "\n",
        "def merge_val_test(val_dataset: Dataset, test_dataset: Dataset):\n",
        "    return ConcatDataset([val_dataset, test_dataset])\n",
        "\n",
        "\n",
        "def save_dataset(dataset, file_path):\n",
        "    os.makedirs(os.path.dirname(file_path), exist_ok=True)\n",
        "    with open(file_path, \"wb\") as f:\n",
        "        pickle.dump(dataset, f)\n",
        "    print(f\"Dataset saved to {file_path}.\")\n",
        "\n",
        "\n",
        "def load_dataset(file_path):\n",
        "    with open(file_path, 'rb') as file:\n",
        "        dataset = pickle.load(file)\n",
        "    print(f\"Dataset loaded from {file_path}.\")\n",
        "    return dataset"
      ],
      "metadata": {
        "id": "IYhT-ZLSM1dj"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GoogleSpeechDataset(Dataset):\n",
        "    \"\"\"Dataset wrapper for Google Speech Commands V2 to save, since output is in numpy array.\"\"\"\n",
        "\n",
        "    def __init__(self, data_list: list, audio_settings: dict, label_map: dict = None):\n",
        "        super().__init__()\n",
        "\n",
        "        self.data_list = data_list\n",
        "        self.audio_settings = audio_settings\n",
        "\n",
        "        # labels: if no label map is provided, will not load labels. (Use for inference)\n",
        "        if label_map is not None:\n",
        "            self.label_list = []\n",
        "            label_2_idx = {v: int(k) for k, v in label_map.items()}\n",
        "            for path in data_list:\n",
        "                # Store the integer index instead of the string label\n",
        "                self.label_list.append(label_2_idx[path.split(\"/\")[-2]])\n",
        "        else:\n",
        "            self.label_list = None\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_list)\n",
        "\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x = librosa.load(self.data_list[idx], sr=self.audio_settings[\"sr\"])[0]\n",
        "\n",
        "        # this will return MFCC for saved .pkl file (in numpy array)\n",
        "        x = librosa.util.fix_length(x, size=self.audio_settings[\"sr\"])\n",
        "        x = librosa.feature.melspectrogram(y=x, **self.audio_settings)\n",
        "        x = librosa.feature.mfcc(S=librosa.power_to_db(x), n_mfcc=self.audio_settings[\"n_mels\"])\n",
        "\n",
        "        if self.label_list is not None:\n",
        "            label = self.label_list[idx]\n",
        "            return x, label\n",
        "        else:\n",
        "            return x"
      ],
      "metadata": {
        "id": "sjCWrfkP9BCE"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import ConcatDataset, Dataset\n",
        "import pickle\n",
        "\n",
        "class PrecomputedSpeechDataset(Dataset):\n",
        "    \"\"\"\n",
        "        API ~ GoogleSpeechDataset, use when training to ensure real-time spec_aug\n",
        "        __getitem__ -> (x, label) if label else x\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, pkl_path, aug_settings: dict = None, label_map: dict = None, train=False):\n",
        "        super().__init__()\n",
        "        self.dataset = load_dataset(pkl_path)   # list of (x, label) or [x]\n",
        "        self.aug_settings = aug_settings\n",
        "        self.train = train\n",
        "\n",
        "        # labels: same as GoogleSpeechDataset\n",
        "        if label_map is not None:\n",
        "            self.label_list = []\n",
        "            #label_2_idx = {v: int(k) for k, v in label_map.items()}\n",
        "            # The label map is not needed here anymore since the labels in the pickle file\n",
        "            # are already integer indices.\n",
        "            for sample in self.dataset:\n",
        "                if isinstance(sample, tuple) and len(sample) == 2:\n",
        "                    _, y = sample\n",
        "                    self.label_list.append(y) # Use the integer label directly\n",
        "                else:\n",
        "                    self.label_list.append(None)\n",
        "        else:\n",
        "            self.label_list = None\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sample = self.dataset[idx]\n",
        "\n",
        "        if isinstance(sample, tuple) and len(sample) == 2:\n",
        "            x, y = sample\n",
        "        else:\n",
        "            x, y = sample, None\n",
        "\n",
        "        # augment\n",
        "        if self.train and self.aug_settings is not None:\n",
        "            if \"spec_aug\" in self.aug_settings:\n",
        "                x = spec_augment(x, **self.aug_settings[\"spec_aug\"])\n",
        "\n",
        "        if isinstance(x, np.ndarray):\n",
        "            x = torch.from_numpy(x).float()\n",
        "        if x.ndim == 2:\n",
        "            x = x.unsqueeze(0)  # (n_MFCC, T)\n",
        "\n",
        "        if self.label_list is not None:\n",
        "            label = self.label_list[idx]\n",
        "            label = torch.tensor(label, dtype=torch.long)\n",
        "            return x, label\n",
        "        elif y is not None:\n",
        "            y = torch.tensor(y, dtype=torch.long)\n",
        "            return x, y\n",
        "        else:\n",
        "            return x"
      ],
      "metadata": {
        "id": "uGuyVA5fFBsS"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_loader(dataset, config, train=True):\n",
        "  dataloader = DataLoader(\n",
        "      dataset,\n",
        "      batch_size=config[\"hparams\"][\"batch_size\"],\n",
        "      num_workers=config[\"exp\"][\"n_workers\"],\n",
        "      pin_memory=config[\"exp\"][\"pin_memory\"],\n",
        "      shuffle=True if train else False\n",
        "  )\n",
        "\n",
        "  return dataloader"
      ],
      "metadata": {
        "id": "7ILxcfIMBncx"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Download Google Speech Commands V2 dataset"
      ],
      "metadata": {
        "id": "wuvUsYwHsC3f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "download_gspeech_v2_str = \"\"\"\n",
        "#!/bin/bash\n",
        "\n",
        "data_dir=$1\n",
        "curr_dir=$PWD\n",
        "\n",
        "mkdir -p $data_dir\n",
        "\n",
        "cd $data_dir\n",
        "wget http://download.tensorflow.org/data/speech_commands_v0.02.tar.gz -O - | tar -xz\n",
        "\n",
        "cd $curr_dir\"\"\"\n",
        "\n",
        "with open('download_gspeech_v2.sh', 'w') as f:\n",
        "    f.write(download_gspeech_v2_str)\n",
        "\n",
        "!sh ./download_gspeech_v2.sh ./data/"
      ],
      "metadata": {
        "id": "6vVGXuhevDhe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a20a720-27ba-4144-c124-638704e1986b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-08-20 12:37:44--  http://download.tensorflow.org/data/speech_commands_v0.02.tar.gz\n",
            "Resolving download.tensorflow.org (download.tensorflow.org)... 142.250.145.207, 74.125.128.207, 74.125.143.207, ...\n",
            "Connecting to download.tensorflow.org (download.tensorflow.org)|142.250.145.207|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2428923189 (2.3G) [application/gzip]\n",
            "Saving to: ‘STDOUT’\n",
            "\n",
            "-                   100%[===================>]   2.26G  40.4MB/s    in 59s     \n",
            "\n",
            "2025-08-20 12:38:44 (39.1 MB/s) - written to stdout [2428923189/2428923189]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls data"
      ],
      "metadata": {
        "id": "z6X5jMO2xGmq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e7f42b1-0839-4fb6-a890-f842f2ea8c9e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "_background_noise_  five     left     README.md\t\ttree\n",
            "backward\t    follow   LICENSE  right\t\ttwo\n",
            "bed\t\t    forward  marvin   seven\t\tup\n",
            "bird\t\t    four     nine     sheila\t\tvalidation_list.txt\n",
            "cat\t\t    go\t     no       six\t\tvisual\n",
            "dog\t\t    happy    off      stop\t\twow\n",
            "down\t\t    house    on       testing_list.txt\tyes\n",
            "eight\t\t    learn    one      three\t\tzero\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " The dataset provides a `validation_list.txt` and a `testing_list.txt` as the split. We'll run a simple script `make_data_list.py` to also generate a `training_list.txt`, as well as a `label_map.json` that maps numeric indices to class labels."
      ],
      "metadata": {
        "id": "LUEpfMbcxMbV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Validate dataset directory"
      ],
      "metadata": {
        "id": "MfPNvaK9P6yN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def walk_through_dir(dir_path):\n",
        "  for dirpath, dirnames, filenames in os.walk(dir_path):\n",
        "    print(f\"There are {len(dirnames)} directories and {len(filenames)} files in '{dirpath}'.\")\n",
        "\n",
        "data_path = './data/'\n",
        "walk_through_dir(data_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GoVCcpSvbdG2",
        "outputId": "b5c9261f-a1ea-4be7-e431-ad9e51c8abde"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 36 directories and 5 files in './data/'.\n",
            "There are 0 directories and 1579 files in './data/follow'.\n",
            "There are 0 directories and 2031 files in './data/cat'.\n",
            "There are 0 directories and 1557 files in './data/forward'.\n",
            "There are 0 directories and 3880 files in './data/go'.\n",
            "There are 0 directories and 3860 files in './data/six'.\n",
            "There are 0 directories and 2123 files in './data/wow'.\n",
            "There are 0 directories and 4044 files in './data/yes'.\n",
            "There are 0 directories and 3934 files in './data/nine'.\n",
            "There are 0 directories and 3801 files in './data/left'.\n",
            "There are 0 directories and 2014 files in './data/bed'.\n",
            "There are 0 directories and 2022 files in './data/sheila'.\n",
            "There are 0 directories and 3890 files in './data/one'.\n",
            "There are 0 directories and 2113 files in './data/house'.\n",
            "There are 0 directories and 1575 files in './data/learn'.\n",
            "There are 0 directories and 3941 files in './data/no'.\n",
            "There are 0 directories and 2064 files in './data/bird'.\n",
            "There are 0 directories and 3778 files in './data/right'.\n",
            "There are 0 directories and 3845 files in './data/on'.\n",
            "There are 0 directories and 1664 files in './data/backward'.\n",
            "There are 0 directories and 3745 files in './data/off'.\n",
            "There are 0 directories and 3723 files in './data/up'.\n",
            "There are 0 directories and 3998 files in './data/seven'.\n",
            "There are 0 directories and 7 files in './data/_background_noise_'.\n",
            "There are 0 directories and 3728 files in './data/four'.\n",
            "There are 0 directories and 4052 files in './data/zero'.\n",
            "There are 0 directories and 3880 files in './data/two'.\n",
            "There are 0 directories and 2128 files in './data/dog'.\n",
            "There are 0 directories and 3917 files in './data/down'.\n",
            "There are 0 directories and 4052 files in './data/five'.\n",
            "There are 0 directories and 2054 files in './data/happy'.\n",
            "There are 0 directories and 2100 files in './data/marvin'.\n",
            "There are 0 directories and 3787 files in './data/eight'.\n",
            "There are 0 directories and 3872 files in './data/stop'.\n",
            "There are 0 directories and 1759 files in './data/tree'.\n",
            "There are 0 directories and 1592 files in './data/visual'.\n",
            "There are 0 directories and 3727 files in './data/three'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "testing_list_path = '/content/data/testing_list.txt'\n",
        "\n",
        "def get_classes(content):\n",
        "    classes = set()\n",
        "    for line in content.splitlines():\n",
        "        parts = line.split('/')\n",
        "        if len(parts) > 3:\n",
        "            classes.add(parts[2])\n",
        "        else:\n",
        "            classes.add(parts[0])\n",
        "    return classes\n",
        "\n",
        "\n",
        "with open(testing_list_path, 'r') as file:\n",
        "    content = file.read()\n",
        "    #print(content)\n",
        "    class_set = get_classes(content)\n",
        "    print(class_set)\n",
        "    print(len(class_set))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u9R6pvq-aksC",
        "outputId": "23a02f0b-79fb-4a7b-ab1e-e2898256ce52"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'no', 'bird', 'left', 'five', 'house', 'forward', 'bed', 'one', 'dog', 'learn', 'two', 'down', 'three', 'eight', 'nine', 'right', 'zero', 'up', 'off', 'stop', 'on', 'marvin', 'seven', 'four', 'visual', 'follow', 'tree', 'six', 'backward', 'wow', 'go', 'yes', 'sheila', 'cat', 'happy'}\n",
            "35\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.1 Get loader from .pkl file\n",
        "1. Create 3 Dataset train - val - test\n",
        "2. Merge val - test\n",
        "3. Save as .pkl file\n",
        "4. Load .pkl file and change into dataloader"
      ],
      "metadata": {
        "id": "lwGryUAj83bB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "#from utils.dataset import get_train_val_test_split\n",
        "from torch.utils import data\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import functools\n",
        "import librosa\n",
        "import glob\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import multiprocessing as mp\n",
        "import json\n",
        "\n",
        "#from utils.augment import time_shift, resample, spec_augment\n",
        "from audiomentations import AddBackgroundNoise\n",
        "\n",
        "\n",
        "def get_train_val_test_split(root: str, val_file: str, test_file: str):\n",
        "    \"\"\"Creates train, val, and test split according to provided val and test files.\n",
        "\n",
        "    Args:\n",
        "        root (str): Path to base directory of the dataset.\n",
        "        val_file (str): Path to file containing list of validation data files.\n",
        "        test_file (str): Path to file containing list of test data files.\n",
        "\n",
        "    Returns:\n",
        "        train_list (list): List of paths to training data items.\n",
        "        val_list (list): List of paths to validation data items.\n",
        "        test_list (list): List of paths to test data items.\n",
        "        label_map (dict): Mapping of indices to label classes.\n",
        "    \"\"\"\n",
        "\n",
        "    ####################\n",
        "    # Labels\n",
        "    ####################\n",
        "\n",
        "    label_list = [label for label in sorted(os.listdir(root)) if os.path.isdir(os.path.join(root, label)) and label[0] != \"_\"]\n",
        "    label_map = {idx: label for idx, label in enumerate(label_list)}\n",
        "\n",
        "    ###################\n",
        "    # Split\n",
        "    ###################\n",
        "\n",
        "    all_files_set = set()\n",
        "    for label in label_list:\n",
        "        all_files_set.update(set(glob.glob(os.path.join(root, label, \"*.wav\"))))\n",
        "\n",
        "    with open(val_file, \"r\") as f:\n",
        "        val_files_set = set(map(lambda a: os.path.join(root, a), f.read().rstrip(\"\\n\").split(\"\\n\")))\n",
        "\n",
        "    with open(test_file, \"r\") as f:\n",
        "        test_files_set = set(map(lambda a: os.path.join(root, a), f.read().rstrip(\"\\n\").split(\"\\n\")))\n",
        "\n",
        "    assert len(val_files_set.intersection(test_files_set)) == 0, \"Sanity check: No files should be common between val and test.\"\n",
        "\n",
        "    all_files_set -= val_files_set\n",
        "    all_files_set -= test_files_set\n",
        "\n",
        "    train_list, val_list, test_list = list(all_files_set), list(val_files_set), list(test_files_set)\n",
        "\n",
        "    print(f\"Number of training samples: {len(train_list)}\")\n",
        "    print(f\"Number of validation samples: {len(val_list)}\")\n",
        "    print(f\"Number of test samples: {len(test_list)}\")\n",
        "\n",
        "    return train_list, val_list, test_list, label_map\n",
        "\n",
        "def generate_data_lists(val_list_file, test_list_file, data_root, out_dir):\n",
        "\n",
        "    train_list, val_list, test_list, label_map = get_train_val_test_split(data_root, val_list_file, test_list_file)\n",
        "\n",
        "    with open(os.path.join(out_dir, \"training_list.txt\"), \"w+\") as f:\n",
        "        f.write(\"\\n\".join(train_list))\n",
        "\n",
        "    with open(os.path.join(out_dir, \"validation_list.txt\"), \"w+\") as f:\n",
        "        f.write(\"\\n\".join(val_list))\n",
        "\n",
        "    with open(os.path.join(out_dir, \"testing_list.txt\"), \"w+\") as f:\n",
        "        f.write(\"\\n\".join(test_list))\n",
        "\n",
        "    with open(os.path.join(out_dir, \"label_map.json\"), \"w+\") as f:\n",
        "        json.dump(label_map, f)\n",
        "\n",
        "    print(\"Saved data lists and label map.\")\n"
      ],
      "metadata": {
        "id": "sAjv9w6B3kUL"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_data_lists('./data/validation_list.txt', './data/testing_list.txt', './data/', './data/')"
      ],
      "metadata": {
        "id": "6KJBn3xNy_5O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8099cc5-7880-45cc-f2f8-d53d7124b112"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training samples: 84843\n",
            "Number of validation samples: 9981\n",
            "Number of test samples: 11005\n",
            "Saved data lists and label map.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_pkl_data(conf_file):\n",
        "  config = get_config(conf_file)\n",
        "\n",
        "  with open(config[\"label_map\"], \"r\") as f:\n",
        "    label_map = json.load(f)\n",
        "\n",
        "  with open(config[\"train_list_file\"], \"r\") as f:\n",
        "    train_list = f.read().rstrip().split(\"\\n\")\n",
        "\n",
        "  with open(config[\"test_list_file\"], \"r\") as f:\n",
        "    test_list = f.read().rstrip().split(\"\\n\")\n",
        "\n",
        "  with open(config[\"val_list_file\"], \"r\") as f:\n",
        "    val_list = f.read().rstrip().split(\"\\n\")\n",
        "\n",
        "  train_first_dataset = GoogleSpeechDataset(data_list=train_list,\n",
        "                                            audio_settings=config[\"hparams\"][\"audio\"],\n",
        "                                            label_map=label_map)\n",
        "  test_first_dataset = GoogleSpeechDataset(data_list=test_list,\n",
        "                                           audio_settings=config[\"hparams\"][\"audio\"],\n",
        "                                           label_map=label_map)\n",
        "  val_first_dataset = GoogleSpeechDataset(data_list=val_list,\n",
        "                                          audio_settings=config[\"hparams\"][\"audio\"],\n",
        "                                          label_map=label_map)\n",
        "\n",
        "  test_merged_dataset = merge_val_test(val_first_dataset, test_first_dataset)\n",
        "\n",
        "  save_dataset(train_first_dataset, config[\"pkl_train\"])\n",
        "  save_dataset(test_merged_dataset, config[\"pkl_test\"])"
      ],
      "metadata": {
        "id": "MisKif0xzjLW"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "create_pkl_data(conf_file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rcZpLhf0f_ic",
        "outputId": "243da616-e813-48ea-ffe4-2f1702e2c879"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset saved to ./google_speech_commands_v2/train_dataset.pkl.\n",
            "Dataset saved to ./google_speech_commands_v2/test_dataset.pkl.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set up for training functions"
      ],
      "metadata": {
        "id": "Oho0QtlQv7T0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- `misc.py` Miscellaneous helper functions."
      ],
      "metadata": {
        "id": "U3BwE3845Y0b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Miscellaneous helper functions.\"\"\"\n",
        "\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "import numpy as np\n",
        "import random\n",
        "import os\n",
        "import wandb\n",
        "\n",
        "\n",
        "def seed_everything(seed: str) -> None:\n",
        "\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    print(f'Set seed {seed}')\n",
        "\n",
        "\n",
        "def count_params(model: nn.Module) -> int:\n",
        "    return sum(map(lambda p: p.data.numel(), model.parameters()))\n",
        "\n",
        "\n",
        "def calc_step(epoch: int, n_batches: int, batch_index: int) -> int:\n",
        "    return (epoch - 1) * n_batches + (1 + batch_index)\n",
        "\n",
        "\n",
        "def log(log_dict: dict, step: int, config: dict) -> None:\n",
        "    \"\"\"Handles logging for metric tracking server, local disk and stdout.\n",
        "\n",
        "    Args:\n",
        "        log_dict (dict): Log metric dict.\n",
        "        step (int): Current step.\n",
        "        config (dict): Config dict.\n",
        "    \"\"\"\n",
        "    log_message = f\"Step: {step} | \" + \" | \".join([f\"{k}: {v}\" for k, v in log_dict.items()])\n",
        "\n",
        "    # write logs to disk\n",
        "    if config[\"exp\"][\"log_to_file\"]:\n",
        "        log_file = os.path.join(config[\"exp\"][\"save_dir\"], \"training_log.txt\")\n",
        "\n",
        "        with open(log_file, \"a+\") as f:\n",
        "            f.write(log_message + \"\\n\")\n",
        "\n",
        "    # show logs in stdout\n",
        "    if config[\"exp\"][\"log_to_stdout\"]:\n",
        "        print(log_message)\n",
        "\n",
        "\n",
        "def get_model(model_config: dict) -> nn.Module:\n",
        "\n",
        "    if model_config[\"name\"] is not None:\n",
        "        return kwt_from_name(model_config[\"name\"])\n",
        "    else:\n",
        "        return KWT(**model_config)\n",
        "\n",
        "\n",
        "def save_model(epoch: int, val_acc: float, save_path: str, net: nn.Module, optimizer : optim.Optimizer = None, log_file : str = None) -> None:\n",
        "\n",
        "    ckpt_dict = {\n",
        "        \"epoch\": epoch,\n",
        "        \"val_acc\": val_acc,\n",
        "        \"model_state_dict\": net.state_dict(),\n",
        "        \"optimizer_state_dict\": optimizer.state_dict() if optimizer is not None else optimizer\n",
        "    }\n",
        "\n",
        "    torch.save(ckpt_dict, save_path)\n",
        "\n",
        "    log_message = f\"Saved {save_path} with accuracy {val_acc}.\"\n",
        "    print(log_message)\n",
        "\n",
        "    if log_file is not None:\n",
        "        with open(log_file, \"a+\") as f:\n",
        "            f.write(log_message + \"\\n\")\n"
      ],
      "metadata": {
        "id": "r_2QRjIz5db1"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- LR Scheduler - Cosine\n",
        "- Optimizer"
      ],
      "metadata": {
        "id": "tsFOSZxlzAsI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import optim, nn\n",
        "from torch.optim import lr_scheduler\n",
        "\n",
        "\n",
        "class WarmUpLR(lr_scheduler._LRScheduler):\n",
        "\n",
        "    def __init__(self, optimizer: optim.Optimizer, total_iters: int, last_epoch: int = -1):\n",
        "        \"\"\"Initializer for WarmUpLR\"\"\"\n",
        "\n",
        "        self.total_iters = total_iters\n",
        "        super().__init__(optimizer, last_epoch)\n",
        "\n",
        "    def get_lr(self):\n",
        "        \"\"\"Learning rate will be set to base_lr * last_epoch / total_iters.\"\"\"\n",
        "\n",
        "        return [base_lr * self.last_epoch / (self.total_iters + 1e-8) for base_lr in self.base_lrs]\n",
        "\n",
        "\n",
        "def get_scheduler(optimizer: optim.Optimizer, scheduler_type: str, T_max: int) -> lr_scheduler._LRScheduler:\n",
        "\n",
        "    if scheduler_type == \"cosine_annealing\":\n",
        "        scheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max, eta_min=1e-8)\n",
        "    else:\n",
        "        raise ValueError(f\"Unsupported scheduler type: {scheduler_type}\")\n",
        "\n",
        "    return scheduler\n",
        "\n",
        "from torch import nn, optim\n",
        "\n",
        "\n",
        "def get_optimizer(net: nn.Module, opt_config: dict) -> optim.Optimizer:\n",
        "\n",
        "    if opt_config[\"opt_type\"] == \"adamw\":\n",
        "        optimizer = optim.AdamW(net.parameters(), **opt_config[\"opt_kwargs\"])\n",
        "    else:\n",
        "        raise ValueError(f'Unsupported optimizer {opt_config[\"opt_type\"]}')\n",
        "\n",
        "    return optimizer\n"
      ],
      "metadata": {
        "id": "EivM5fdLy_8M"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- LabelSmoothingLoss"
      ],
      "metadata": {
        "id": "NsnSe03r4x4d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LabelSmoothingLoss(nn.Module):\n",
        "\n",
        "    def __init__(self, num_classes: int, smoothing : float = 0.1, dim : int = -1):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        self.confidence = 1.0 - smoothing\n",
        "        self.smoothing = smoothing\n",
        "        self.cls = num_classes\n",
        "        self.dim = dim\n",
        "\n",
        "    def forward(self, pred: torch.Tensor, target: torch.Tensor) -> torch.Tensor:\n",
        "\n",
        "        assert 0 <= self.smoothing < 1\n",
        "        pred = pred.log_softmax(dim=self.dim)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            true_dist = torch.zeros_like(pred)\n",
        "            true_dist.fill_(self.smoothing / (self.cls - 1))\n",
        "            true_dist.scatter_(1, target.data.unsqueeze(1), self.confidence)\n",
        "        return torch.mean(torch.sum(-true_dist * pred, dim=self.dim))"
      ],
      "metadata": {
        "id": "UN0II9cF4vJC"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Training"
      ],
      "metadata": {
        "id": "Q7_S9dcx4vd_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- `trainer.py` - `train` and `evaluate` function\n",
        "\n"
      ],
      "metadata": {
        "id": "6g0bGQbz58p1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn, optim\n",
        "from typing import Callable, Tuple\n",
        "from torch.utils.data import DataLoader\n",
        "#from utils.misc import log, save_model\n",
        "import os\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "def train_single_batch(net: nn.Module, data: torch.Tensor, targets: torch.Tensor, optimizer: optim.Optimizer, criterion: Callable, device: torch.device) -> Tuple[float, int]:\n",
        "    \"\"\"Performs a single training step.\"\"\"\n",
        "\n",
        "    data, targets = data.to(device), targets.to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    outputs = net(data)\n",
        "    loss = criterion(outputs, targets)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    correct = outputs.argmax(1).eq(targets).sum()\n",
        "    return loss.item(), correct.item()\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(net: nn.Module, criterion: Callable, dataloader: DataLoader, device: torch.device) -> Tuple[float, float]:\n",
        "    \"\"\"Performs inference.\n",
        "\n",
        "    Args:\n",
        "        net (nn.Module): Model instance.\n",
        "        criterion (Callable): Loss function.\n",
        "        dataloader (DataLoader): Test or validation loader.\n",
        "        device (torch.device): Device.\n",
        "\n",
        "    Returns:\n",
        "        accuracy (float): Accuracy.\n",
        "        float: Loss scalar.\n",
        "    \"\"\"\n",
        "\n",
        "    net.eval()\n",
        "    correct = 0\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for data, targets in tqdm(dataloader):\n",
        "        data, targets = data.to(device), targets.to(device)\n",
        "        out = net(data)\n",
        "        correct += out.argmax(1).eq(targets).sum().item()\n",
        "        loss = criterion(out, targets)\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    net.train()\n",
        "    accuracy = correct / len(dataloader.dataset)\n",
        "    return accuracy, running_loss / len(dataloader)\n",
        "\n",
        "\n",
        "def train(net: nn.Module, optimizer: optim.Optimizer, criterion: Callable, trainloader: DataLoader, schedulers: dict, config: dict) -> None:\n",
        "    \"\"\"Trains model.\n",
        "\n",
        "    Args:\n",
        "        net (nn.Module): Model instance.\n",
        "        optimizer (optim.Optimizer): Optimizer instance.\n",
        "        criterion (Callable): Loss function.\n",
        "        trainloader (DataLoader): Training data loader.\n",
        "        schedulers (dict): Dict containing schedulers.\n",
        "        config (dict): Config dict.\n",
        "    \"\"\"\n",
        "\n",
        "    step = 0\n",
        "    best_acc = 0.0 #\n",
        "    n_batches = len(trainloader)\n",
        "    device = config[\"hparams\"][\"device\"]\n",
        "    log_file = os.path.join(config[\"exp\"][\"save_dir\"], \"training_log.txt\")\n",
        "\n",
        "    ############################\n",
        "    # start training\n",
        "    ############################\n",
        "    net.train()\n",
        "\n",
        "    for epoch in range(config[\"hparams\"][\"n_epochs\"]):\n",
        "        t0 = time.time()\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "\n",
        "        for batch_index, (data, targets) in enumerate(trainloader):\n",
        "\n",
        "            if schedulers[\"warmup\"] is not None and epoch < config[\"hparams\"][\"scheduler\"][\"n_warmup\"]:\n",
        "                schedulers[\"warmup\"].step()\n",
        "\n",
        "            elif schedulers[\"scheduler\"] is not None:\n",
        "                schedulers[\"scheduler\"].step()\n",
        "\n",
        "            ####################\n",
        "            # optimization step\n",
        "            ####################\n",
        "\n",
        "            loss, corr = train_single_batch(net, data, targets, optimizer, criterion, device)\n",
        "            running_loss += loss\n",
        "            correct += corr\n",
        "\n",
        "            if not step % config[\"exp\"][\"log_freq\"]:\n",
        "                log_dict = {\"epoch\": epoch, \"loss\": loss, \"lr\": optimizer.param_groups[0][\"lr\"]}\n",
        "                log(log_dict, step, config)\n",
        "\n",
        "            step += 1\n",
        "\n",
        "        #######################\n",
        "        # epoch complete\n",
        "        #######################\n",
        "        train_acc = correct / len(trainloader.dataset)\n",
        "        log_dict = {\n",
        "            \"epoch\": epoch,\n",
        "            \"time_per_epoch\": time.time() - t0,\n",
        "            \"train_acc\": train_acc,\n",
        "            \"avg_loss_per_ep\": running_loss / len(trainloader)\n",
        "        }\n",
        "        log(log_dict, step, config)\n",
        "\n",
        "        # save best model based on train acc\n",
        "        if train_acc > best_acc:\n",
        "            best_acc = train_acc\n",
        "            save_path = os.path.join(config[\"exp\"][\"save_dir\"], \"best.pth\")\n",
        "            save_model(epoch, train_acc, save_path, net, optimizer, log_file)\n",
        "\n",
        "    ###########################\n",
        "    # training complete\n",
        "    ###########################\n",
        "\n",
        "    # save final ckpt\n",
        "    save_path = os.path.join(config[\"exp\"][\"save_dir\"], \"last.pth\")\n",
        "    save_model(epoch, train_acc, save_path, net, optimizer, log_file)\n"
      ],
      "metadata": {
        "id": "N71MESnl58GF"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`train.py`"
      ],
      "metadata": {
        "id": "giQbJN5W9Fu8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "import yaml\n",
        "import torch\n",
        "import wandb\n",
        "import random\n",
        "import time\n",
        "\n",
        "from argparse import ArgumentParser\n",
        "# from config_parser import get_config\n",
        "# from utils.loss import LabelSmoothingLoss\n",
        "# from utils.opt import get_optimizer\n",
        "# from utils.scheduler import WarmUpLR, get_scheduler\n",
        "# from utils.trainer import train, evaluate\n",
        "# from utils.dataset import get_train_val_test_split, get_loader\n",
        "# from utils.misc import seed_everything, count_params, get_model, calc_step, log\n",
        "\n",
        "def training_pipeline(config):\n",
        "    \"\"\"Initiates and executes all the steps involved with model training.\n",
        "\n",
        "    Args:\n",
        "        config (dict) - Dict containing various settings for the training run.\n",
        "    \"\"\"\n",
        "    start_func_time = time.time()\n",
        "    # Get label map\n",
        "    with open(config[\"label_map\"], \"r\") as f:\n",
        "      label_map = json.load(f)\n",
        "\n",
        "    config[\"exp\"][\"save_dir\"] = os.path.join(config[\"exp\"][\"exp_dir\"], config[\"exp\"][\"exp_name\"])\n",
        "    os.makedirs(config[\"exp\"][\"save_dir\"], exist_ok=True)\n",
        "\n",
        "    ######################################\n",
        "    # save hyperparameters for current run\n",
        "    ######################################\n",
        "\n",
        "    config_str = yaml.dump(config)\n",
        "    print(\"Using settings:\\n\", config_str)\n",
        "\n",
        "    with open(os.path.join(config[\"exp\"][\"save_dir\"], \"settings.txt\"), \"w+\") as f:\n",
        "        f.write(config_str)\n",
        "\n",
        "    #####################################\n",
        "    # initialize training items\n",
        "    #####################################\n",
        "\n",
        "    # data\n",
        "    train_dataset = PrecomputedSpeechDataset(\n",
        "        pkl_path=config[\"pkl_train\"],\n",
        "        aug_settings = config[\"hparams\"][\"augment\"],\n",
        "        label_map = label_map,\n",
        "        train=True # for data_augment\n",
        "    )\n",
        "\n",
        "    trainloader = get_loader(train_dataset, config, train=True) # for shuffle\n",
        "\n",
        "    # model\n",
        "    model = get_model(config[\"hparams\"][\"model\"])\n",
        "    model = model.to(config[\"hparams\"][\"device\"])\n",
        "    print(f\"Created model with {count_params(model)} parameters.\")\n",
        "\n",
        "    # loss\n",
        "    if config[\"hparams\"][\"l_smooth\"]:\n",
        "        criterion = LabelSmoothingLoss(num_classes=config[\"hparams\"][\"model\"][\"num_classes\"], smoothing=config[\"hparams\"][\"l_smooth\"])\n",
        "    else:\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # optimizer\n",
        "    optimizer = get_optimizer(model, config[\"hparams\"][\"optimizer\"])\n",
        "\n",
        "    # lr scheduler\n",
        "    schedulers = {\n",
        "        \"warmup\": None,\n",
        "        \"scheduler\": None\n",
        "    }\n",
        "\n",
        "    if config[\"hparams\"][\"scheduler\"][\"n_warmup\"]:\n",
        "        schedulers[\"warmup\"] = WarmUpLR(optimizer, total_iters=len(trainloader) * config[\"hparams\"][\"scheduler\"][\"n_warmup\"])\n",
        "\n",
        "    if config[\"hparams\"][\"scheduler\"][\"scheduler_type\"] is not None:\n",
        "        total_iters = len(trainloader) * max(1, (config[\"hparams\"][\"scheduler\"][\"max_epochs\"] - config[\"hparams\"][\"scheduler\"][\"n_warmup\"]))\n",
        "        schedulers[\"scheduler\"] = get_scheduler(optimizer, config[\"hparams\"][\"scheduler\"][\"scheduler_type\"], total_iters)\n",
        "\n",
        "\n",
        "    #####################################\n",
        "    # Training Run\n",
        "    #####################################\n",
        "    end_func_time = time.time()\n",
        "    print(\"Initiating training.\")\n",
        "    print(f\"Takes {end_func_time - start_func_time} seconds to start training.\")\n",
        "    # train(model, optimizer, criterion, trainloader, valloader, schedulers, config)\n",
        "    train(model, optimizer, criterion, trainloader, schedulers, config)\n",
        "\n",
        "    #####################################\n",
        "    # Final Test\n",
        "    #####################################\n",
        "\n",
        "    test_dataset = PrecomputedSpeechDataset(\n",
        "        pkl_path=config[\"pkl_test\"],\n",
        "        aug_settings = config[\"hparams\"][\"augment\"],\n",
        "        label_map = label_map,\n",
        "        train=False\n",
        "    )\n",
        "    testloader = get_loader(test_dataset, config, train=False)\n",
        "    final_step = calc_step(config[\"hparams\"][\"n_epochs\"] + 1, len(trainloader), len(trainloader) - 1)\n",
        "\n",
        "    # evaluating the final state (last.pth)\n",
        "    print(\"Evaluating last ckpt\")\n",
        "    test_acc, test_loss = evaluate(model, criterion, testloader, config[\"hparams\"][\"device\"])\n",
        "    log_dict = {\n",
        "        \"test_loss_last\": test_loss,\n",
        "        \"test_acc_last\": test_acc\n",
        "    }\n",
        "    log(log_dict, final_step, config)\n",
        "\n",
        "    # evaluating the best state (best.pth)\n",
        "    ckpt = torch.load(os.path.join(config[\"exp\"][\"save_dir\"], \"best.pth\"))\n",
        "    model.load_state_dict(ckpt[\"model_state_dict\"])\n",
        "    print(\"Best ckpt loaded - by train_acc.\")\n",
        "\n",
        "    test_acc, test_loss = evaluate(model, criterion, testloader, config[\"hparams\"][\"device\"])\n",
        "    log_dict = {\n",
        "        \"test_loss_best\": test_loss,\n",
        "        \"test_acc_best\": test_acc\n",
        "    }\n",
        "    log(log_dict, final_step, config)\n",
        "\n",
        "def main(conf_file):\n",
        "    config = get_config(conf_file)\n",
        "    seed_everything(config[\"hparams\"][\"seed\"])\n",
        "    training_pipeline(config)\n"
      ],
      "metadata": {
        "id": "d_XXbyfx5BQi"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set up sample configs for KWT-2 with demo training 20 epochs\n",
        "- **cache: here we set = 0 for no cache, enable data augmentation**.\n",
        "- The paper train 140 epochs / 23000 steps."
      ],
      "metadata": {
        "id": "SzXUCOf6v9zc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "main(conf_file)"
      ],
      "metadata": {
        "id": "Jr2jjoug8QRC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23522558-9c20-44b8-ae8e-2b99795b56f2"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Set seed 0\n",
            "Using settings:\n",
            " data_root: ./data/\n",
            "exp:\n",
            "  device: &id001 !!python/object/apply:torch.device\n",
            "  - cuda\n",
            "  exp_dir: ./runs\n",
            "  exp_name: exp-0.0.1\n",
            "  log_freq: 20\n",
            "  log_to_file: false\n",
            "  log_to_stdout: true\n",
            "  n_workers: 1\n",
            "  pin_memory: true\n",
            "  save_dir: ./runs/exp-0.0.1\n",
            "  val_freq: 1\n",
            "hparams:\n",
            "  audio:\n",
            "    center: false\n",
            "    hop_length: 160\n",
            "    n_fft: 480\n",
            "    n_mels: 40\n",
            "    sr: 16000\n",
            "    win_length: 480\n",
            "  augment:\n",
            "    spec_aug:\n",
            "      freq_mask_width: 7\n",
            "      n_freq_masks: 2\n",
            "      n_time_masks: 2\n",
            "      time_mask_width: 25\n",
            "  batch_size: 512\n",
            "  device: *id001\n",
            "  l_smooth: 0.1\n",
            "  model:\n",
            "    depth: 12\n",
            "    dim: 64\n",
            "    dropout: 0.0\n",
            "    emb_dropout: 0.1\n",
            "    heads: 1\n",
            "    input_res:\n",
            "    - 40\n",
            "    - 98\n",
            "    mlp_dim: 256\n",
            "    name: kwt-2\n",
            "    num_classes: 35\n",
            "    patch_res:\n",
            "    - 40\n",
            "    - 1\n",
            "    pre_norm: false\n",
            "  n_epochs: 20\n",
            "  optimizer:\n",
            "    opt_kwargs:\n",
            "      lr: 0.001\n",
            "      weight_decay: 0.1\n",
            "    opt_type: adamw\n",
            "  scheduler:\n",
            "    max_epochs: 140\n",
            "    n_warmup: 10\n",
            "    scheduler_type: cosine_annealing\n",
            "  seed: 0\n",
            "label_map: ./data/label_map.json\n",
            "pkl_root: ./google_speech_commands_v2/\n",
            "pkl_test: ./google_speech_commands_v2/test_dataset.pkl\n",
            "pkl_train: ./google_speech_commands_v2/train_dataset.pkl\n",
            "test_list_file: ./data/testing_list.txt\n",
            "train_list_file: ./data/training_list.txt\n",
            "val_list_file: ./data/validation_list.txt\n",
            "\n",
            "Dataset loaded from ./google_speech_commands_v2/train_dataset.pkl.\n",
            "Created model with 2397475 parameters.\n",
            "Initiating training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/optim/lr_scheduler.py:192: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step: 0 | epoch: 0 | loss: 3.7855935096740723 | lr: 6.024096385505879e-07\n",
            "Step: 20 | epoch: 0 | loss: 3.657698392868042 | lr: 1.2650602409562347e-05\n",
            "Step: 40 | epoch: 0 | loss: 3.534853935241699 | lr: 2.4698795180574107e-05\n",
            "Step: 60 | epoch: 0 | loss: 3.523815631866455 | lr: 3.6746987951585866e-05\n",
            "Step: 80 | epoch: 0 | loss: 3.49392032623291 | lr: 4.879518072259762e-05\n",
            "Step: 100 | epoch: 0 | loss: 3.516051769256592 | lr: 6.0843373493609386e-05\n",
            "Step: 120 | epoch: 0 | loss: 3.49010968208313 | lr: 7.289156626462113e-05\n",
            "Step: 140 | epoch: 0 | loss: 3.4255590438842773 | lr: 8.493975903563291e-05\n",
            "Step: 160 | epoch: 0 | loss: 3.3385000228881836 | lr: 9.698795180664466e-05\n",
            "Step: 166 | epoch: 0 | time_per_epoch: 350.80592131614685 | train_acc: 0.05147154155322183 | avg_loss_per_ep: 3.513685789452978\n",
            "Saved ./runs/exp-0.0.1/best.pth with accuracy 0.05147154155322183.\n",
            "Step: 180 | epoch: 1 | loss: 3.21820068359375 | lr: 0.00010903614457765641\n",
            "Step: 200 | epoch: 1 | loss: 3.2096359729766846 | lr: 0.00012108433734866819\n",
            "Step: 220 | epoch: 1 | loss: 3.075800895690918 | lr: 0.00013313253011967992\n",
            "Step: 240 | epoch: 1 | loss: 3.0019683837890625 | lr: 0.00014518072289069169\n",
            "Step: 260 | epoch: 1 | loss: 2.9933037757873535 | lr: 0.00015722891566170345\n",
            "Step: 280 | epoch: 1 | loss: 2.8836965560913086 | lr: 0.00016927710843271524\n",
            "Step: 300 | epoch: 1 | loss: 2.825078248977661 | lr: 0.00018132530120372697\n",
            "Step: 320 | epoch: 1 | loss: 2.7970826625823975 | lr: 0.00019337349397473874\n",
            "Step: 332 | epoch: 1 | time_per_epoch: 311.5493369102478 | train_acc: 0.19362823096778756 | avg_loss_per_ep: 3.0010818903704726\n",
            "Saved ./runs/exp-0.0.1/best.pth with accuracy 0.19362823096778756.\n",
            "Step: 340 | epoch: 2 | loss: 2.6913974285125732 | lr: 0.0002054216867457505\n",
            "Step: 360 | epoch: 2 | loss: 2.6044278144836426 | lr: 0.00021746987951676224\n",
            "Step: 380 | epoch: 2 | loss: 2.6169042587280273 | lr: 0.000229518072287774\n",
            "Step: 400 | epoch: 2 | loss: 2.580329418182373 | lr: 0.00024156626505878576\n",
            "Step: 420 | epoch: 2 | loss: 2.4912734031677246 | lr: 0.0002536144578297975\n",
            "Step: 440 | epoch: 2 | loss: 2.4813804626464844 | lr: 0.0002656626506008093\n",
            "Step: 460 | epoch: 2 | loss: 2.4934279918670654 | lr: 0.000277710843371821\n",
            "Step: 480 | epoch: 2 | loss: 2.4309897422790527 | lr: 0.00028975903614283276\n",
            "Step: 498 | epoch: 2 | time_per_epoch: 304.1323518753052 | train_acc: 0.3529224567730985 | avg_loss_per_ep: 2.5308677633124663\n",
            "Saved ./runs/exp-0.0.1/best.pth with accuracy 0.3529224567730985.\n",
            "Step: 500 | epoch: 3 | loss: 2.3164608478546143 | lr: 0.00030180722891384455\n",
            "Step: 520 | epoch: 3 | loss: 2.292469024658203 | lr: 0.00031385542168485634\n",
            "Step: 540 | epoch: 3 | loss: 2.3568472862243652 | lr: 0.0003259036144558681\n",
            "Step: 560 | epoch: 3 | loss: 2.3371522426605225 | lr: 0.00033795180722687987\n",
            "Step: 580 | epoch: 3 | loss: 2.331462860107422 | lr: 0.00034999999999789155\n",
            "Step: 600 | epoch: 3 | loss: 2.2966291904449463 | lr: 0.00036204819276890334\n",
            "Step: 620 | epoch: 3 | loss: 2.1567625999450684 | lr: 0.00037409638553991513\n",
            "Step: 640 | epoch: 3 | loss: 2.076601505279541 | lr: 0.00038614457831092686\n",
            "Step: 660 | epoch: 3 | loss: 2.161520481109619 | lr: 0.00039819277108193865\n",
            "Step: 664 | epoch: 3 | time_per_epoch: 304.1377651691437 | train_acc: 0.4315146800561036 | avg_loss_per_ep: 2.30214305096362\n",
            "Saved ./runs/exp-0.0.1/best.pth with accuracy 0.4315146800561036.\n",
            "Step: 680 | epoch: 4 | loss: 2.255577325820923 | lr: 0.0004102409638529504\n",
            "Step: 700 | epoch: 4 | loss: 2.246077537536621 | lr: 0.0004222891566239622\n",
            "Step: 720 | epoch: 4 | loss: 2.126399278640747 | lr: 0.00043433734939497386\n",
            "Step: 740 | epoch: 4 | loss: 2.1374995708465576 | lr: 0.00044638554216598565\n",
            "Step: 760 | epoch: 4 | loss: 2.172645092010498 | lr: 0.00045843373493699744\n",
            "Step: 780 | epoch: 4 | loss: 2.1991500854492188 | lr: 0.0004704819277080092\n",
            "Step: 800 | epoch: 4 | loss: 2.121273994445801 | lr: 0.00048253012047902097\n",
            "Step: 820 | epoch: 4 | loss: 2.1103343963623047 | lr: 0.0004945783132500328\n",
            "Step: 830 | epoch: 4 | time_per_epoch: 305.63313126564026 | train_acc: 0.4811239583701661 | avg_loss_per_ep: 2.1577446080115905\n",
            "Saved ./runs/exp-0.0.1/best.pth with accuracy 0.4811239583701661.\n",
            "Step: 840 | epoch: 5 | loss: 2.056527614593506 | lr: 0.0005066265060210444\n",
            "Step: 860 | epoch: 5 | loss: 2.031339645385742 | lr: 0.0005186746987920562\n",
            "Step: 880 | epoch: 5 | loss: 2.0906314849853516 | lr: 0.000530722891563068\n",
            "Step: 900 | epoch: 5 | loss: 2.108971118927002 | lr: 0.0005427710843340797\n",
            "Step: 920 | epoch: 5 | loss: 2.0374302864074707 | lr: 0.0005548192771050915\n",
            "Step: 940 | epoch: 5 | loss: 2.061431884765625 | lr: 0.0005668674698761033\n",
            "Step: 960 | epoch: 5 | loss: 2.0494508743286133 | lr: 0.000578915662647115\n",
            "Step: 980 | epoch: 5 | loss: 2.02463960647583 | lr: 0.0005909638554181268\n",
            "Step: 996 | epoch: 5 | time_per_epoch: 309.1076557636261 | train_acc: 0.5178034722958877 | avg_loss_per_ep: 2.05181710332273\n",
            "Saved ./runs/exp-0.0.1/best.pth with accuracy 0.5178034722958877.\n",
            "Step: 1000 | epoch: 6 | loss: 1.9672770500183105 | lr: 0.0006030120481891385\n",
            "Step: 1020 | epoch: 6 | loss: 2.012124538421631 | lr: 0.0006150602409601503\n",
            "Step: 1040 | epoch: 6 | loss: 2.0401363372802734 | lr: 0.000627108433731162\n",
            "Step: 1060 | epoch: 6 | loss: 1.92685067653656 | lr: 0.0006391566265021738\n",
            "Step: 1080 | epoch: 6 | loss: 1.9843389987945557 | lr: 0.0006512048192731855\n",
            "Step: 1100 | epoch: 6 | loss: 2.022123098373413 | lr: 0.0006632530120441973\n",
            "Step: 1120 | epoch: 6 | loss: 1.9544473886489868 | lr: 0.0006753012048152091\n",
            "Step: 1140 | epoch: 6 | loss: 1.9101250171661377 | lr: 0.0006873493975862209\n",
            "Step: 1160 | epoch: 6 | loss: 1.968475341796875 | lr: 0.0006993975903572326\n",
            "Step: 1162 | epoch: 6 | time_per_epoch: 325.31291818618774 | train_acc: 0.5425786452624259 | avg_loss_per_ep: 1.9785267459340843\n",
            "Saved ./runs/exp-0.0.1/best.pth with accuracy 0.5425786452624259.\n",
            "Step: 1180 | epoch: 7 | loss: 1.9047589302062988 | lr: 0.0007114457831282443\n",
            "Step: 1200 | epoch: 7 | loss: 1.8933930397033691 | lr: 0.0007234939758992561\n",
            "Step: 1220 | epoch: 7 | loss: 1.974348545074463 | lr: 0.0007355421686702679\n",
            "Step: 1240 | epoch: 7 | loss: 1.8759949207305908 | lr: 0.0007475903614412797\n",
            "Step: 1260 | epoch: 7 | loss: 1.91960871219635 | lr: 0.0007596385542122915\n",
            "Step: 1280 | epoch: 7 | loss: 1.9579663276672363 | lr: 0.0007716867469833031\n",
            "Step: 1300 | epoch: 7 | loss: 1.9354438781738281 | lr: 0.0007837349397543149\n",
            "Step: 1320 | epoch: 7 | loss: 1.9561439752578735 | lr: 0.0007957831325253266\n",
            "Step: 1328 | epoch: 7 | time_per_epoch: 310.14715456962585 | train_acc: 0.563169619178954 | avg_loss_per_ep: 1.9238290434860321\n",
            "Saved ./runs/exp-0.0.1/best.pth with accuracy 0.563169619178954.\n",
            "Step: 1340 | epoch: 8 | loss: 1.8431050777435303 | lr: 0.0008078313252963384\n",
            "Step: 1360 | epoch: 8 | loss: 1.8445723056793213 | lr: 0.0008198795180673501\n",
            "Step: 1380 | epoch: 8 | loss: 1.910568356513977 | lr: 0.0008319277108383619\n",
            "Step: 1400 | epoch: 8 | loss: 1.8004791736602783 | lr: 0.0008439759036093737\n",
            "Step: 1420 | epoch: 8 | loss: 1.880784273147583 | lr: 0.0008560240963803855\n",
            "Step: 1440 | epoch: 8 | loss: 1.8074418306350708 | lr: 0.0008680722891513973\n",
            "Step: 1460 | epoch: 8 | loss: 1.8294981718063354 | lr: 0.0008801204819224091\n",
            "Step: 1480 | epoch: 8 | loss: 1.9580256938934326 | lr: 0.0008921686746934207\n",
            "Step: 1494 | epoch: 8 | time_per_epoch: 309.4240155220032 | train_acc: 0.5794821022358946 | avg_loss_per_ep: 1.8744182550763508\n",
            "Saved ./runs/exp-0.0.1/best.pth with accuracy 0.5794821022358946.\n",
            "Step: 1500 | epoch: 9 | loss: 1.9416770935058594 | lr: 0.0009042168674644325\n",
            "Step: 1520 | epoch: 9 | loss: 1.854694128036499 | lr: 0.0009162650602354443\n",
            "Step: 1540 | epoch: 9 | loss: 1.7382562160491943 | lr: 0.000928313253006456\n",
            "Step: 1560 | epoch: 9 | loss: 1.792366862297058 | lr: 0.0009403614457774677\n",
            "Step: 1580 | epoch: 9 | loss: 1.8252753019332886 | lr: 0.0009524096385484795\n",
            "Step: 1600 | epoch: 9 | loss: 1.8142088651657104 | lr: 0.0009644578313194913\n",
            "Step: 1620 | epoch: 9 | loss: 1.8564741611480713 | lr: 0.0009765060240905031\n",
            "Step: 1640 | epoch: 9 | loss: 1.8627567291259766 | lr: 0.0009885542168615149\n",
            "Step: 1660 | epoch: 9 | time_per_epoch: 307.2705099582672 | train_acc: 0.5836073689049185 | avg_loss_per_ep: 1.8594167763928333\n",
            "Saved ./runs/exp-0.0.1/best.pth with accuracy 0.5836073689049185.\n",
            "Step: 1660 | epoch: 10 | loss: 1.858818769454956 | lr: 0.000999999994695725\n",
            "Step: 1680 | epoch: 10 | loss: 1.920170783996582 | lr: 0.000999997663467096\n",
            "Step: 1700 | epoch: 10 | loss: 1.8617620468139648 | lr: 0.000999991093660453\n",
            "Step: 1720 | epoch: 10 | loss: 1.9483171701431274 | lr: 0.0009999802853314901\n",
            "Step: 1740 | epoch: 10 | loss: 1.844792366027832 | lr: 0.0009999652385718318\n",
            "Step: 1760 | epoch: 10 | loss: 1.8160006999969482 | lr: 0.0009999459535090342\n",
            "Step: 1780 | epoch: 10 | loss: 1.8812443017959595 | lr: 0.0009999224303065826\n",
            "Step: 1800 | epoch: 10 | loss: 1.8297849893569946 | lr: 0.0009998946691638895\n",
            "Step: 1820 | epoch: 10 | loss: 2.0106430053710938 | lr: 0.0009998626703162932\n",
            "Step: 1826 | epoch: 10 | time_per_epoch: 310.0849463939667 | train_acc: 0.5763586860436335 | avg_loss_per_ep: 1.883240913770285\n",
            "Step: 1840 | epoch: 11 | loss: 1.9156525135040283 | lr: 0.0009998264340350576\n",
            "Step: 1860 | epoch: 11 | loss: 1.990410566329956 | lr: 0.0009997859606273678\n",
            "Step: 1880 | epoch: 11 | loss: 2.0421156883239746 | lr: 0.0009997412504363283\n",
            "Step: 1900 | epoch: 11 | loss: 1.905656099319458 | lr: 0.0009996923038409601\n",
            "Step: 1920 | epoch: 11 | loss: 2.0756256580352783 | lr: 0.0009996391212561968\n",
            "Step: 1940 | epoch: 11 | loss: 1.9279080629348755 | lr: 0.0009995817031328818\n",
            "Step: 1960 | epoch: 11 | loss: 2.0956201553344727 | lr: 0.0009995200499577652\n",
            "Step: 1980 | epoch: 11 | loss: 2.067006826400757 | lr: 0.0009994541622534983\n",
            "Step: 1992 | epoch: 11 | time_per_epoch: 307.92963576316833 | train_acc: 0.5236849239182961 | avg_loss_per_ep: 2.0295261180544473\n",
            "Step: 2000 | epoch: 12 | loss: 2.1103127002716064 | lr: 0.0009993840405786289\n",
            "Step: 2020 | epoch: 12 | loss: 2.066882610321045 | lr: 0.000999309685527599\n",
            "Step: 2040 | epoch: 12 | loss: 2.0675225257873535 | lr: 0.000999231097730737\n",
            "Step: 2060 | epoch: 12 | loss: 2.1335840225219727 | lr: 0.0009991482778542531\n",
            "Step: 2080 | epoch: 12 | loss: 2.063753604888916 | lr: 0.0009990612266002358\n",
            "Step: 2100 | epoch: 12 | loss: 2.081644058227539 | lr: 0.0009989699447066423\n",
            "Step: 2120 | epoch: 12 | loss: 1.9812519550323486 | lr: 0.0009988744329472944\n",
            "Step: 2140 | epoch: 12 | loss: 2.106849193572998 | lr: 0.000998774692131872\n",
            "Step: 2158 | epoch: 12 | time_per_epoch: 306.85205817222595 | train_acc: 0.5033296795257122 | avg_loss_per_ep: 2.082693946648793\n",
            "Step: 2160 | epoch: 13 | loss: 2.112490177154541 | lr: 0.000998670723105907\n",
            "Step: 2180 | epoch: 13 | loss: 2.220580577850342 | lr: 0.0009985625267507731\n",
            "Step: 2200 | epoch: 13 | loss: 2.0659255981445312 | lr: 0.0009984501039836814\n",
            "Step: 2220 | epoch: 13 | loss: 2.0606682300567627 | lr: 0.0009983334557576715\n",
            "Step: 2240 | epoch: 13 | loss: 2.1329307556152344 | lr: 0.0009982125830616027\n",
            "Step: 2260 | epoch: 13 | loss: 2.0565619468688965 | lr: 0.0009980874869201465\n",
            "Step: 2280 | epoch: 13 | loss: 2.1917262077331543 | lr: 0.0009979581683937783\n",
            "Step: 2300 | epoch: 13 | loss: 2.0663318634033203 | lr: 0.000997824628578768\n",
            "Step: 2320 | epoch: 13 | loss: 2.0584282875061035 | lr: 0.00099768686860717\n",
            "Step: 2324 | epoch: 13 | time_per_epoch: 311.9374907016754 | train_acc: 0.5033061065733178 | avg_loss_per_ep: 2.087130660752216\n",
            "Step: 2340 | epoch: 14 | loss: 2.0650315284729004 | lr: 0.0009975448896468132\n",
            "Step: 2360 | epoch: 14 | loss: 2.0637102127075195 | lr: 0.0009973986929012945\n",
            "Step: 2380 | epoch: 14 | loss: 2.188140630722046 | lr: 0.000997248279609963\n",
            "Step: 2400 | epoch: 14 | loss: 2.047278881072998 | lr: 0.0009970936510479151\n",
            "Step: 2420 | epoch: 14 | loss: 1.9561057090759277 | lr: 0.0009969348085259809\n",
            "Step: 2440 | epoch: 14 | loss: 1.9722046852111816 | lr: 0.0009967717533907131\n",
            "Step: 2460 | epoch: 14 | loss: 2.125638961791992 | lr: 0.0009966044870243751\n",
            "Step: 2480 | epoch: 14 | loss: 2.0451626777648926 | lr: 0.0009964330108449306\n",
            "Step: 2490 | epoch: 14 | time_per_epoch: 306.15332531929016 | train_acc: 0.5132067465789752 | avg_loss_per_ep: 2.057762215654534\n",
            "Step: 2500 | epoch: 15 | loss: 2.051409959793091 | lr: 0.0009962573263060323\n",
            "Step: 2520 | epoch: 15 | loss: 2.0350821018218994 | lr: 0.0009960774348970066\n",
            "Step: 2540 | epoch: 15 | loss: 1.9875526428222656 | lr: 0.0009958933381428439\n",
            "Step: 2560 | epoch: 15 | loss: 2.187244415283203 | lr: 0.0009957050376041832\n",
            "Step: 2580 | epoch: 15 | loss: 1.9677296876907349 | lr: 0.0009955125348773022\n",
            "Step: 2600 | epoch: 15 | loss: 2.0981719493865967 | lr: 0.0009953158315940994\n",
            "Step: 2620 | epoch: 15 | loss: 2.023589849472046 | lr: 0.0009951149294220839\n",
            "Step: 2640 | epoch: 15 | loss: 2.003011703491211 | lr: 0.0009949098300643605\n",
            "Step: 2656 | epoch: 15 | time_per_epoch: 303.8426082134247 | train_acc: 0.5197010949636387 | avg_loss_per_ep: 2.038291266165584\n",
            "Step: 2660 | epoch: 16 | loss: 1.9750694036483765 | lr: 0.0009947005352596132\n",
            "Step: 2680 | epoch: 16 | loss: 1.8844138383865356 | lr: 0.0009944870467820928\n",
            "Step: 2700 | epoch: 16 | loss: 1.9899046421051025 | lr: 0.0009942693664416011\n",
            "Step: 2720 | epoch: 16 | loss: 1.9832772016525269 | lr: 0.0009940474960834756\n",
            "Step: 2740 | epoch: 16 | loss: 1.9345648288726807 | lr: 0.0009938214375885739\n",
            "Step: 2760 | epoch: 16 | loss: 1.9168376922607422 | lr: 0.0009935911928732556\n",
            "Step: 2780 | epoch: 16 | loss: 1.9675873517990112 | lr: 0.0009933567638893712\n",
            "Step: 2800 | epoch: 16 | loss: 1.925696849822998 | lr: 0.0009931181526242408\n",
            "Step: 2820 | epoch: 16 | loss: 1.877577543258667 | lr: 0.0009928753611006386\n",
            "Step: 2822 | epoch: 16 | time_per_epoch: 303.6267559528351 | train_acc: 0.5424254210718621 | avg_loss_per_ep: 1.9718666428543\n",
            "Step: 2840 | epoch: 17 | loss: 1.9124959707260132 | lr: 0.0009926283913767766\n",
            "Step: 2860 | epoch: 17 | loss: 1.89046311378479 | lr: 0.0009923772455462869\n",
            "Step: 2880 | epoch: 17 | loss: 2.0181779861450195 | lr: 0.000992121925738202\n",
            "Step: 2900 | epoch: 17 | loss: 2.005936861038208 | lr: 0.00099186243411694\n",
            "Step: 2920 | epoch: 17 | loss: 1.9760820865631104 | lr: 0.0009915987728822844\n",
            "Step: 2940 | epoch: 17 | loss: 1.8942527770996094 | lr: 0.0009913309442693653\n",
            "Step: 2960 | epoch: 17 | loss: 1.849661111831665 | lr: 0.0009910589505486408\n",
            "Step: 2980 | epoch: 17 | loss: 1.9449098110198975 | lr: 0.0009907827940258788\n",
            "Step: 2988 | epoch: 17 | time_per_epoch: 314.09051036834717 | train_acc: 0.5500984170762467 | avg_loss_per_ep: 1.9520985067608845\n",
            "Step: 3000 | epoch: 18 | loss: 1.9771367311477661 | lr: 0.000990502477042135\n",
            "Step: 3020 | epoch: 18 | loss: 1.876176357269287 | lr: 0.000990218001973734\n",
            "Step: 3040 | epoch: 18 | loss: 1.8927878141403198 | lr: 0.0009899293712322527\n",
            "Step: 3060 | epoch: 18 | loss: 1.8653101921081543 | lr: 0.0009896365872644928\n",
            "Step: 3080 | epoch: 18 | loss: 1.91428804397583 | lr: 0.0009893396525524675\n",
            "Step: 3100 | epoch: 18 | loss: 1.8117690086364746 | lr: 0.0009890385696133752\n",
            "Step: 3120 | epoch: 18 | loss: 1.8271818161010742 | lr: 0.00098873334099958\n",
            "Step: 3140 | epoch: 18 | loss: 1.8308217525482178 | lr: 0.000988423969298591\n",
            "Step: 3154 | epoch: 18 | time_per_epoch: 306.2648365497589 | train_acc: 0.5686267576582629 | avg_loss_per_ep: 1.895747867693384\n",
            "Step: 3160 | epoch: 19 | loss: 1.8703091144561768 | lr: 0.0009881104571330395\n",
            "Step: 3180 | epoch: 19 | loss: 1.9821573495864868 | lr: 0.0009877928071606544\n",
            "Step: 3200 | epoch: 19 | loss: 1.8376744985580444 | lr: 0.000987471022074245\n",
            "Step: 3220 | epoch: 19 | loss: 1.9137694835662842 | lr: 0.0009871451046016733\n",
            "Step: 3240 | epoch: 19 | loss: 1.9384825229644775 | lr: 0.0009868150575058322\n",
            "Step: 3260 | epoch: 19 | loss: 1.8674793243408203 | lr: 0.0009864808835846248\n",
            "Step: 3280 | epoch: 19 | loss: 1.9317938089370728 | lr: 0.0009861425856709368\n",
            "Step: 3300 | epoch: 19 | loss: 1.9407930374145508 | lr: 0.0009858001666326144\n",
            "Step: 3320 | epoch: 19 | time_per_epoch: 310.15455746650696 | train_acc: 0.562497790035713 | avg_loss_per_ep: 1.909999461777239\n",
            "Saved ./runs/exp-0.0.1/last.pth with accuracy 0.562497790035713.\n",
            "Dataset loaded from ./google_speech_commands_v2/test_dataset.pkl.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 41/41 [01:09<00:00,  1.70s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step: 3486 | test_loss_last: 1.4416520944455775 | test_acc_last: 0.7336319451062613\n",
            "Best ckpt loaded.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 41/41 [01:11<00:00,  1.74s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step: 3486 | test_loss_best: 1.3598168681307536 | test_acc_best: 0.7709901839321452\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}